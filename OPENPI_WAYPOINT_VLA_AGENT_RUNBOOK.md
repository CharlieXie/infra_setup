# OpenPI Waypoint VLA â€” AI Agent Runbookï¼ˆç»éªŒç‰ˆï¼‰

> **ç›®æ ‡è¯»è€…**: AI Agentã€‚æœ¬æ–‡æ¡£è®°å½•äº†åœ¨å…¨æ–° vast.ai æœåŠ¡å™¨ä¸Šä»é›¶åˆ°è®­ç»ƒå¯åŠ¨çš„å®Œæ•´æ“ä½œæµç¨‹ï¼ŒåŒ…å«æ‰€æœ‰å®é™…è¸©å‘ç»†èŠ‚å’Œä¿®å¤æ–¹æ³•ã€‚ä¸ `OPENPI_WAYPOINT_VLA_SETUP.md`ï¼ˆè®¾è®¡è§„èŒƒç‰ˆï¼‰ç»“åˆä½¿ç”¨ã€‚
>
> **æœ€åéªŒè¯**: 2026-02-21ï¼Œç¡¬ä»¶: 2Ã— RTX PRO 6000 Blackwell (97.9 GB)ï¼ŒUbuntu 24.04ï¼ŒCUDA 12.8
>
> **è¦†ç›–èŒƒå›´**: Action Expert (AE) è®­ç»ƒ + VLM waypoint è®­ç»ƒ
>
> **å®æµ‹æ€»è€—æ—¶ï¼ˆä» clone åˆ° step=0ï¼‰: ~15 åˆ†é’Ÿ**ï¼ˆuv syncã€æ•°æ®ä¸‹è½½ã€æ¨¡å‹ä¸‹è½½ä¸‰è·¯å¹¶è¡Œï¼‰

---

## Agent è¡Œä¸ºå‡†åˆ™ï¼ˆå¿…é¡»éµå®ˆï¼‰

1. **`sleep` æœ€å¤š 30 ç§’**ã€‚å•æ¬¡ `sleep` ä¸å¾—è¶…è¿‡ 30sã€‚éœ€è¦ç­‰å¾…é•¿æ—¶é—´ä»»åŠ¡æ—¶ï¼Œæ”¹ç”¨å¾ªç¯è½®è¯¢ï¼ˆæ¯æ¬¡ sleep â‰¤ 30sï¼Œæ£€æŸ¥çŠ¶æ€ï¼Œå† sleepï¼‰ã€‚
2. **åå°ä»»åŠ¡ç”¨ `&` å¯åŠ¨**ï¼Œè¾“å‡ºé‡å®šå‘åˆ°æ–‡ä»¶ï¼Œä¹‹åé€šè¿‡ `tail` è¯»æ–‡ä»¶æ£€æŸ¥è¿›åº¦ï¼Œä¸è¦ç”¨ `block_until_ms > 30000` çš„é˜»å¡å¼è°ƒç”¨ã€‚
3. **tmux send-keys æ¯æ¬¡åªå‘ä¸€æ¡å‘½ä»¤**ã€‚ä¸è¦åœ¨åŒä¸€ä¸ª `send-keys` é‡Œæ‹¼æ¥å¤šæ¡å‘½ä»¤ï¼Œé¿å… bash è§£ææ··ä¹±ã€‚å…ˆå‘ `cd` å’Œ `export`ï¼Œå†å•ç‹¬å‘è®­ç»ƒå‘½ä»¤ã€‚
4. **å‘ç°é”™è¯¯ç«‹åˆ»è¯»æ—¥å¿—**ï¼Œä¸è¦ç›²ç›®é‡è¯•ã€‚æ¯æ¬¡å¤±è´¥åå…ˆ `tail -50 <logfile>` å®šä½æ ¹å› ã€‚
5. **è·¯å¾„ä¸¥æ ¼æŒ‰ç…§æœ¬æ–‡æ¡£**ï¼Œä¸è¦è‡ªè¡Œå‘æ˜è·¯å¾„ã€‚æ‰€æœ‰æ•°æ®/æ¨¡å‹/æ—¥å¿—è·¯å¾„å·²åœ¨ä¸‹æ–¹åˆ—å‡ºã€‚

---

## ç›®å½•

1. [å¿«é€Ÿ Checklist](#1-å¿«é€Ÿ-checklist)
2. [åŸºç¡€ç¯å¢ƒå‡†å¤‡](#2-åŸºç¡€ç¯å¢ƒå‡†å¤‡)
3. [å…‹éš†ä»£ç ä»“åº“](#3-å…‹éš†ä»£ç ä»“åº“)
4. [é…ç½® Python ç¯å¢ƒï¼ˆuv syncï¼‰](#4-é…ç½®-python-ç¯å¢ƒuv-sync)
5. [å®‰è£…é¢å¤–ä¾èµ–](#5-å®‰è£…é¢å¤–ä¾èµ–)
6. [åº”ç”¨ transformers è¡¥ä¸](#6-åº”ç”¨-transformers-è¡¥ä¸)
7. [é…ç½® rclone Google Drive](#7-é…ç½®-rclone-google-drive)
8. [ä¸‹è½½è®­ç»ƒæ•°æ®](#8-ä¸‹è½½è®­ç»ƒæ•°æ®)
9. [ç”Ÿæˆ dataset_statisticsï¼ˆå¿…é¡»æ‰‹åŠ¨è®¡ç®—ï¼‰](#9-ç”Ÿæˆ-dataset_statisticså¿…é¡»æ‰‹åŠ¨è®¡ç®—)
   - 9.1â€“9.2: AE ç”¨ statsï¼ˆä»åŸå§‹ RLDSï¼‰
   - 9.3: **VLM ç”¨ stats**ï¼ˆä» waypoint-filtered RLDSï¼‰
10. [ä¸‹è½½å¹¶è½¬æ¢ pi0.5 base æ¨¡å‹](#10-ä¸‹è½½å¹¶è½¬æ¢-pi05-base-æ¨¡å‹)
11. [é…ç½® wandb](#11-é…ç½®-wandb)
12. [å¯åŠ¨è®­ç»ƒ](#12-å¯åŠ¨è®­ç»ƒ)
    - 12.1â€“12.2: AE è®­ç»ƒ
    - 12.4â€“12.5: **VLM è®­ç»ƒ**
13. [éªŒè¯è®­ç»ƒæ­£å¸¸](#13-éªŒè¯è®­ç»ƒæ­£å¸¸)
    - 13.1: AE éªŒè¯
    - 13.2: **VLM éªŒè¯**
14. [å·²çŸ¥é—®é¢˜ä¸ä¿®å¤æ–¹æ¡ˆ](#14-å·²çŸ¥é—®é¢˜ä¸ä¿®å¤æ–¹æ¡ˆ)
    - é—®é¢˜ 1â€“6: AE / é€šç”¨
    - é—®é¢˜ 7â€“10: **VLM ä¸“å±**
15. [å…³é”®è·¯å¾„é€ŸæŸ¥](#15-å…³é”®è·¯å¾„é€ŸæŸ¥)

---

## 1. å¿«é€Ÿ Checklist

```
â–¡ touch ~/.no_auto_tmux  ï¼ˆé‡è¿åç”Ÿæ•ˆï¼‰
â–¡ git config --global user.email/name
â–¡ sudo apt-get install -y ffmpeg pkg-config build-essential
â–¡ cd /workspace && git clone openpi (pytorch_lora_blackwell branch)
â–¡ git submodule update --init --recursive
â–¡ æ£€æŸ¥ pyproject.toml æ˜¯å¦å·²å« av>=13.1.0,<14.0.0ï¼ˆé€šå¸¸å·²æœ‰ï¼Œæ— éœ€ä¿®æ”¹ï¼‰
â–¡ ã€å¹¶è¡Œå¯åŠ¨ä»¥ä¸‹ä¸‰è·¯ï¼Œä¸è¦ç­‰å¾…ã€‘
  â–¡ cd /workspace/openpi && GIT_LFS_SKIP_SMUDGE=1 uv sync > /tmp/uv_sync.log 2>&1 &          (3-10 min)
  â–¡ rclone copy gg1:dissert_ntu/libero/libero_object_no_noops/ ... -P --transfers=8 &          (~1 min)
  â–¡ rclone copy gg1:dissert_ntu/libero/libero_object_wp_001/ ... -P --transfers=4 &            (~1 min)
  â–¡ gsutil -m cp -r gs://openpi-assets/checkpoints/pi05_base /workspace/models/pi05_base_jax/ & (~2 min)
â–¡ é…ç½® rclone gg1ï¼ˆè‹¥è¿˜æœªé…ç½®ï¼Œåœ¨ä¸‹è½½å‰å®Œæˆï¼‰
â–¡ é…ç½® wandb â†’ å†™å…¥ ~/.netrc
â–¡ ç­‰ uv sync å®Œæˆ â†’ uv pip install tensorflow==2.15.0 tensorflow-datasets==4.9.3
â–¡ cp -r ./src/openpi/models_pytorch/transformers_replace/* .venv/lib/python3.11/site-packages/transformers/
â–¡ ç­‰æ•°æ®ä¸‹è½½å®Œæˆ â†’ æ‰‹åŠ¨ç”Ÿæˆ dataset_statistics.jsonï¼ˆè§ç¬¬ 9 èŠ‚ï¼Œå¿…é¡»åšï¼çº¦ 50sï¼‰
â–¡ ç­‰ gsutil å®Œæˆ â†’ è½¬æ¢ä¸º PyTorch: .venv/bin/python examples/convert_jax_model_to_pytorch.py ...  (~2 min)
â–¡ ã€AE è®­ç»ƒã€‘æ£€æŸ¥æ‰€æœ‰è·¯å¾„ï¼ˆè§ç¬¬ 12.1 èŠ‚ï¼‰ â†’ åˆ›å»º tmux session â†’ å¯åŠ¨è®­ç»ƒ â†’ æ£€æŸ¥ step=0 loss
â–¡ ã€VLM è®­ç»ƒã€‘ç”Ÿæˆ VLM ä¸“ç”¨ norm statsï¼ˆè§ç¬¬ 9.3 èŠ‚ï¼‰ â†’ æ£€æŸ¥è·¯å¾„ï¼ˆç¬¬ 12.4 èŠ‚ï¼‰ â†’ å¯åŠ¨è®­ç»ƒï¼ˆç¬¬ 12.5 èŠ‚ï¼‰ â†’ æ£€æŸ¥ loss
```

---

## 2. åŸºç¡€ç¯å¢ƒå‡†å¤‡

```bash
# ç¦ç”¨ vast.ai è‡ªåŠ¨ tmux
touch ~/.no_auto_tmux
# é‡è¿åç”Ÿæ•ˆ

# é…ç½® git èº«ä»½
git config --global user.email "chuanliang.xie@gmail.com"
git config --global user.name "chuanliang"

# å®‰è£…æ„å»ºä¾èµ–ï¼ˆuv sync éœ€è¦ï¼‰
sudo apt-get install -y ffmpeg pkg-config build-essential
```

> **æ³¨æ„**: vast.ai é•œåƒé€šå¸¸é¢„è£… `uv`ï¼ˆ`/usr/local/bin/uv`ï¼‰å’Œ `rclone`ï¼Œæ— éœ€é‡æ–°å®‰è£…ã€‚æ‰§è¡Œå‰å…ˆæ£€æŸ¥ï¼š
> ```bash
> which uv && uv --version
> rclone --version
> ```

---

## 3. å…‹éš†ä»£ç ä»“åº“

```bash
cd /workspace

# openpi ä¸»ä»“åº“ï¼ˆå« waypoint VLA å®ç°ï¼‰
git clone https://<PAT>@github.com/CharlieXie/openpi.git
cd openpi
git checkout pytorch_lora_blackwell
git submodule update --init --recursive

# infra_setupï¼ˆæœ¬æ–‡æ¡£æ‰€åœ¨ä»“åº“ï¼‰
cd /workspace
git clone https://<PAT>@github.com/CharlieXie/infra_setup.git
```

éªŒè¯åˆ†æ”¯ï¼š
```bash
cd /workspace/openpi && git branch  # åº”æ˜¾ç¤º * pytorch_lora_blackwell
```

---

## 4. é…ç½® Python ç¯å¢ƒï¼ˆuv syncï¼‰

### 4.1 ç¡®è®¤ `av` ç‰ˆæœ¬ override æ˜¯å¦å·²å­˜åœ¨

`openpi` é€šè¿‡ `lerobot` ä¾èµ– `av` åŒ…ã€‚`av >= 14.0` è¦æ±‚ ffmpeg 7 ä»æºç ç¼–è¯‘ï¼Œè€Œ Ubuntu 22/24 ç³»ç»Ÿåªæœ‰ ffmpeg 6ã€‚éœ€è¦åœ¨ `pyproject.toml` çš„ `[tool.uv]` ä¸­æ·»åŠ  overrideï¼Œå¼ºåˆ¶ä½¿ç”¨æœ‰é¢„ç¼–è¯‘ wheel çš„ `av 13.x`ã€‚

**å…ˆæ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ï¼ˆ`pytorch_lora_blackwell` åˆ†æ”¯é€šå¸¸å·²é¢„ç½®ï¼Œæ— éœ€ä¿®æ”¹ï¼‰ï¼š**
```bash
grep "override-dependencies" /workspace/openpi/pyproject.toml
# æœŸæœ›è¾“å‡ºåŒ…å«: "av>=13.1.0,<14.0.0"
```

å¦‚æœè¾“å‡ºä¸­**å·²åŒ…å«** `av>=13.1.0,<14.0.0`ï¼Œè·³è¿‡ä¸‹é¢çš„ä¿®å¤æ­¥éª¤ï¼Œç›´æ¥è¿›å…¥ 4.2ã€‚

å¦‚æœ**ä¸åŒ…å«**ï¼Œæ‰§è¡Œä¿®å¤ï¼š
```bash
sed -i 's/override-dependencies = \["ml-dtypes==0.4.1", "tensorstore==0.1.74"\]/override-dependencies = ["ml-dtypes==0.4.1", "tensorstore==0.1.74", "av>=13.1.0,<14.0.0"]/' /workspace/openpi/pyproject.toml
# éªŒè¯ä¿®æ”¹
grep "override-dependencies" /workspace/openpi/pyproject.toml
```

### 4.2 åå°è¿è¡Œ uv sync

```bash
cd /workspace/openpi
GIT_LFS_SKIP_SMUDGE=1 uv sync > /tmp/uv_sync.log 2>&1 &
echo "uv sync PID=$!"
```

ç›‘æ§ï¼ˆæ¯æ¬¡ sleep â‰¤ 30sï¼‰ï¼š
```bash
# æ¯éš” 30s æ£€æŸ¥ä¸€æ¬¡
sleep 30 && tail -10 /tmp/uv_sync.log
# é‡å¤ç›´åˆ°çœ‹åˆ° "Resolved" / "Installed" æˆ– error
```

> **å®æµ‹è€—æ—¶**: vast.ai æœåŠ¡å™¨ä¸Šçº¦ **3â€“10 åˆ†é’Ÿ**ï¼ˆå–å†³äºç½‘é€Ÿå’Œç¼“å­˜çŠ¶æ€ï¼‰ã€‚æ–‡æ¡£æ—§ç‰ˆé¢„ä¼° 10â€“20 åˆ†é’Ÿåä¿å®ˆã€‚**å»ºè®® uv sync åå°è¿è¡Œçš„åŒæ—¶ç«‹å³å¯åŠ¨æ•°æ®ä¸‹è½½å’Œæ¨¡å‹ä¸‹è½½ï¼ˆè§å¹¶è¡Œæ‰§è¡Œå»ºè®®ï¼‰ã€‚**

å®ŒæˆåéªŒè¯ï¼š
```bash
/workspace/openpi/.venv/bin/python -c "import torch; print(torch.__version__)"   # 2.7.x+cu128
/workspace/openpi/.venv/bin/python -c "import jax; print(jax.__version__)"       # 0.5.x
/workspace/openpi/.venv/bin/python -c "import transformers; print(transformers.__version__)"  # 4.53.x
```

---

## âš¡ å¹¶è¡Œæ‰§è¡Œå»ºè®®ï¼ˆèŠ‚çœ ~30 åˆ†é’Ÿï¼‰

å„æ­¥éª¤ä¹‹é—´å­˜åœ¨ä¾èµ–å…³ç³»ï¼Œä½†å¤šä¸ªè€—æ—¶æ“ä½œå¯ä»¥å¹¶è¡Œã€‚**æ¨èæ‰§è¡Œé¡ºåº**ï¼š

```
å…‹éš† openpi & submodule
        â”‚
        â”œâ”€â”€â–º ã€åå°ã€‘uv sync â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º è£…TF & æ‰“patch â”€â”€â”€â”€â”€â”€â”
        â”‚                                                                     â”‚
        â”œâ”€â”€â–º é…ç½® rclone gg1                                                  â”‚
        â”‚        â”‚                                                            â–¼
        â”‚        â”œâ”€â”€â–º ã€åå°ã€‘rclone ä¸‹è½½ libero_object_no_noops â”€â”€â–º è®¡ç®—stats  â”œâ”€â”€â–º å¯åŠ¨è®­ç»ƒ
        â”‚        â””â”€â”€â–º ã€åå°ã€‘rclone ä¸‹è½½ libero_object_wp_001                 â”‚
        â”‚                                                                     â”‚
        â””â”€â”€â–º ã€åå°ã€‘gsutil ä¸‹è½½ JAX checkpoint â”€â”€â–º è½¬æ¢ PyTorch â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

- `uv sync`ã€`rclone` ä¸‹è½½ã€`gsutil` ä¸‹è½½ä¸‰è·¯**åŒæ—¶åœ¨åå°å¯åŠ¨**ï¼Œå®æµ‹æ€»è€—æ—¶çº¦ 15 åˆ†é’Ÿ
- `uv sync` å®Œæˆåç«‹å³æ‰§è¡Œç¬¬ 5ã€6 èŠ‚ï¼ˆè£… TFã€æ‰“ patchï¼‰
- `rclone` ä¸‹è½½å®Œæˆåç«‹å³æ‰§è¡Œç¬¬ 9 èŠ‚ï¼ˆè®¡ç®— statsï¼‰
- `gsutil` ä¸‹è½½å®Œæˆåç«‹å³æ‰§è¡Œç¬¬ 10.3 èŠ‚ï¼ˆæ¨¡å‹è½¬æ¢ï¼‰

---

## 5. å®‰è£…é¢å¤–ä¾èµ–

`uv sync` ä¸åŒ…å« TensorFlowï¼Œä½† RLDS æ•°æ®åŠ è½½å¿…é¡»ç”¨å®ƒï¼š

```bash
cd /workspace/openpi
uv pip install --python .venv/bin/python \
    "tensorflow==2.15.0" \
    "tensorflow-datasets==4.9.3"
```

> **âš ï¸ å¿…é¡»ç”¨ 2.15.0**ï¼Œä¸èƒ½ç”¨æ›´æ–°ç‰ˆæœ¬ã€‚`tensorflow>=2.16` ä¸ `ml_dtypes` æœ‰å†²çªï¼Œä¼šæŠ¥ï¼š
> `AttributeError: module 'ml_dtypes' has no attribute 'int2'`

éªŒè¯ï¼š
```bash
/workspace/openpi/.venv/bin/python -c "
import tensorflow as tf; import tensorflow_datasets as tfds
print('TF:', tf.__version__, 'TFDS:', tfds.__version__)
"
# æœŸæœ›: TF: 2.15.0 TFDS: 4.9.3
```

---

## 6. åº”ç”¨ transformers è¡¥ä¸

```bash
cd /workspace/openpi
cp -r ./src/openpi/models_pytorch/transformers_replace/* \
    .venv/lib/python3.11/site-packages/transformers/
```

éªŒè¯ï¼š
```bash
.venv/bin/python -c "
from transformers.models.siglip import check
assert check.check_whether_transformers_replace_is_installed_correctly()
print('transformers patch OK')
"
```

---

## 7. é…ç½® rclone Google Drive

Remote åç§°å¿…é¡»ä¸º **`gg1`**ï¼ˆè®­ç»ƒé…ç½®æ–‡ä»¶å’Œæœ¬æ–‡æ¡£æ‰€æœ‰å‘½ä»¤éƒ½ç”¨è¿™ä¸ªåå­—ï¼‰ã€‚

### Headless æœåŠ¡å™¨ OAuth æµç¨‹

åœ¨**æœ¬åœ°æœºå™¨**è¿è¡Œï¼š
```bash
rclone authorize "drive"
# æµè§ˆå™¨æˆæƒåï¼Œç»ˆç«¯è¾“å‡º JSON tokenï¼Œå¤åˆ¶æ•´æ®µ
```

åœ¨**æœåŠ¡å™¨**å†™å…¥é…ç½®ï¼š
```bash
mkdir -p ~/.config/rclone
cat > ~/.config/rclone/rclone.conf << 'EOF'
[gg1]
type = drive
scope = drive
token = <ç²˜è´´ä¸Šé¢çš„ JSON token>
EOF
```

éªŒè¯ï¼š
```bash
rclone lsd gg1:  # åº”è¯¥åˆ—å‡º Google Drive æ ¹ç›®å½•
rclone lsd gg1:dissert_ntu/libero  # åº”è¯¥çœ‹åˆ° libero_object_no_noops å’Œ libero_object_wp_001
```

---

## 8. ä¸‹è½½è®­ç»ƒæ•°æ®

```bash
mkdir -p /workspace/data/libero/libero_object_no_noops \
         /workspace/data/libero/libero_object_wp_001

# åå°ä¸‹è½½ï¼Œä¸¤ä¸ªä»»åŠ¡å¹¶è¡Œ
rclone copy gg1:dissert_ntu/libero/libero_object_no_noops/ \
    /workspace/data/libero/libero_object_no_noops/ \
    -P --transfers=8 > /tmp/rclone_rlds.log 2>&1 &

rclone copy gg1:dissert_ntu/libero/libero_object_wp_001/ \
    /workspace/data/libero/libero_object_wp_001/ \
    -P --transfers=4 > /tmp/rclone_wp.log 2>&1 &

echo "Both downloads started"
```

ç›‘æ§è¿›åº¦ï¼ˆâ‰¤ 30s sleepï¼‰ï¼š
```bash
sleep 30 && tail -5 /tmp/rclone_rlds.log && tail -5 /tmp/rclone_wp.log
```

å®ŒæˆåéªŒè¯æ–‡ä»¶æ•°é‡ï¼š
```bash
ls /workspace/data/libero/libero_object_no_noops/libero_object_no_noops/1.0.0/ | wc -l
# æœŸæœ›: 34  (32 ä¸ª tfrecord + dataset_info.json + features.json)

ls /workspace/data/libero/libero_object_wp_001/waypoint_filtered_rlds__libero/1.0.0/ | wc -l
# æœŸæœ›: 6  (4 ä¸ª tfrecord + dataset_info.json + features.json)

ls /workspace/data/libero/libero_object_wp_001/waypoint_indices.json
# å¿…é¡»å­˜åœ¨
```

---

## 9. ç”Ÿæˆ dataset_statisticsï¼ˆå¿…é¡»æ‰‹åŠ¨è®¡ç®—ï¼‰

> **âš ï¸ å…³é”®é™·é˜±ï¼** Google Drive ä¸Šå­˜å‚¨çš„ `dataset_statistics.json` æ–‡ä»¶æœ‰å¤šä¸ªç‰ˆæœ¬ï¼Œå¤§å¤šæ•°æ˜¯ä¸º**å…¶ä»–ä»»åŠ¡**ï¼ˆVLM è®­ç»ƒ/R1 æœºå™¨äººï¼‰ç”Ÿæˆçš„ï¼Œaction ç»´åº¦ä¸åŒ¹é…ï¼š
>
> | æ–‡ä»¶æ¥æº | action ç»´åº¦ | ç”¨é€” |
> |---------|------------|------|
> | `models/traind_vlm_models/dataset_statistics.json` | 15 ç»´ | VLM è®­ç»ƒï¼ˆwaypoint filteredï¼‰ |
> | `models/trained_action_expert_1/dataset_statistics.json` | 14 ç»´ | R1 Lite æœºå™¨äºº |
> | `models/libero_ar/dataset_statistics.json` | 9 ç»´ | å…¶ä»–å®éªŒ |
>
> **AE è®­ç»ƒéœ€è¦çš„æ˜¯ LIBERO åŸå§‹ action = 7 ç»´ï¼Œproprio = 8 ç»´ã€‚** å¿…é¡»ä»ä¸‹è½½çš„ RLDS æ•°æ®é‡æ–°è®¡ç®—ã€‚

### 9.1 å…ˆç¡®è®¤ LIBERO çš„ observation key

LIBERO RLDS ä¸­ï¼š
- action key: `"action"` (7 ç»´: 6 å…³èŠ‚ + 1 å¤¹çˆª)
- proprio key: **`"state"`** (8 ç»´: 7 å…³èŠ‚ä½ç½® + 1 å¤¹çˆªä½ç½®)

> **âš ï¸ ä¸è¦ç”¨ `"joint_state"` key**ï¼Œé‚£åªæœ‰ 7 ç»´ï¼ˆç¼ºå°‘å¤¹çˆªï¼‰ã€‚`robot_config.py` é‡Œ `make_libero_config()` æŒ‡å®šçš„æ˜¯ `state_obs_keys=["state"]`ï¼Œ`actual_proprio_dim=8`ã€‚

### 9.2 è¿è¡Œè®¡ç®—è„šæœ¬

```bash
cd /workspace/openpi
mkdir -p /workspace/data/libero_object_no_noops/1.0.0

.venv/bin/python - << 'PYEOF'
import os; os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'
import tensorflow as tf; tf.config.set_visible_devices([], 'GPU')
import tensorflow_datasets as tfds
import numpy as np, json

print('Loading LIBERO RLDS...')
b = tfds.builder_from_directory(
    '/workspace/data/libero/libero_object_no_noops/libero_object_no_noops/1.0.0')
ds = b.as_dataset(split='train')

all_actions, all_proprios = [], []
for ep in ds:
    for step in ep['steps']:
        all_actions.append(step['action'].numpy().astype('float32'))
        all_proprios.append(step['observation']['state'].numpy().astype('float32').flatten())

all_actions = np.stack(all_actions)
all_proprios = np.stack(all_proprios)
print(f'Actions: {all_actions.shape}, Proprios: {all_proprios.shape}')
# æœŸæœ›: Actions: (66984, 7), Proprios: (66984, 8)

def stats(arr):
    return {
        'mean': arr.mean(0).tolist(), 'std': arr.std(0).tolist(),
        'q01': np.percentile(arr, 1, 0).tolist(),
        'q99': np.percentile(arr, 99, 0).tolist(),
        'min': arr.min(0).tolist(), 'max': arr.max(0).tolist(),
    }

out = {'libero_object_no_noops': {
    'action': stats(all_actions),
    'proprio': stats(all_proprios),
    'num_samples': len(all_actions),
}}
path = '/workspace/data/libero_object_no_noops/1.0.0/dataset_statistics.json'
with open(path, 'w') as f:
    json.dump(out, f, indent=2)
print('Saved to', path)
print('action q99:', out['libero_object_no_noops']['action']['q99'])
print('proprio q99 dims:', len(out['libero_object_no_noops']['proprio']['q99']))
# æœŸæœ›: action q99 = 7 values, proprio q99 = 8 values
PYEOF
```

> è¿™ä¸ªè„šæœ¬çº¦éœ€ **45â€“60 ç§’**ï¼Œå¤„ç† 66984 ä¸ªæ—¶é—´æ­¥ã€‚

éªŒè¯ï¼š
```bash
python3 -c "
import json
d = json.load(open('/workspace/data/libero_object_no_noops/1.0.0/dataset_statistics.json'))
k = list(d.keys())[0]
print('dataset:', k)
print('action q99 dims:', len(d[k]['action']['q99']))   # å¿…é¡»æ˜¯ 7
print('proprio q99 dims:', len(d[k]['proprio']['q99'])) # å¿…é¡»æ˜¯ 8
"
```

### 9.3 ç”Ÿæˆ VLM ä¸“ç”¨å½’ä¸€åŒ–ç»Ÿè®¡é‡

> **VLM è®­ç»ƒä½¿ç”¨çš„ stats ä¸ AE ä¸åŒã€‚** VLM ä» waypoint-filtered RLDS è®¡ç®—ç»Ÿè®¡é‡ï¼Œä¿å­˜åˆ°ç‹¬ç«‹è·¯å¾„ã€‚

```bash
cd /workspace/openpi
.venv/bin/python scripts/compute_wp_norm_stats.py \
    --rlds_dir /workspace/data/libero/libero_object_wp_001/waypoint_filtered_rlds__libero/1.0.0 \
    --robot_type libero \
    --output_dir /workspace/data/libero/libero_object_wp_001/norm_stats
```

> è„šæœ¬çº¦éœ€ **30â€“40 ç§’**ï¼Œå¤„ç† 454 episodes, 8863 æ­¥ã€‚

éªŒè¯ï¼š
```bash
python3 -c "
import json
d = json.load(open('/workspace/data/libero/libero_object_wp_001/norm_stats/dataset_statistics.json'))
print('action q99 dims:', len(d['action']['q99']))   # å¿…é¡»æ˜¯ 7
print('proprio q99 dims:', len(d['proprio']['q99'])) # å¿…é¡»æ˜¯ 8
print('num_transitions:', d['num_transitions'])       # 8863
"
```

> **å¦‚æœ `scripts/compute_wp_norm_stats.py` ä¸å­˜åœ¨**ï¼Œå¯ä»¥ç”¨ inline æ–¹å¼ç”Ÿæˆï¼š
> ```bash
> cd /workspace/openpi
> mkdir -p /workspace/data/libero/libero_object_wp_001/norm_stats
> .venv/bin/python - << 'PYEOF'
> import os; os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'
> import tensorflow as tf; tf.config.set_visible_devices([], 'GPU')
> import tensorflow_datasets as tfds
> import numpy as np, json
> b = tfds.builder_from_directory(
>     '/workspace/data/libero/libero_object_wp_001/waypoint_filtered_rlds__libero/1.0.0')
> ds = b.as_dataset(split='train')
> all_a, all_p = [], []
> for ep in ds:
>     for s in ep['steps']:
>         all_a.append(s['action'].numpy().astype('float32'))
>         all_p.append(s['observation']['state'].numpy().astype('float32').flatten())
> all_a, all_p = np.stack(all_a), np.stack(all_p)
> def st(arr):
>     return {'mean':arr.mean(0).tolist(),'std':arr.std(0).tolist(),
>             'q01':np.percentile(arr,1,0).tolist(),'q99':np.percentile(arr,99,0).tolist(),
>             'min':arr.min(0).tolist(),'max':arr.max(0).tolist()}
> out = {'action':st(all_a),'proprio':st(all_p),'num_transitions':len(all_a),'num_trajectories':454}
> path = '/workspace/data/libero/libero_object_wp_001/norm_stats/dataset_statistics.json'
> with open(path,'w') as f: json.dump(out,f,indent=2)
> print(f'Saved to {path}, {len(all_a)} steps')
> PYEOF
> ```

---

## 10. ä¸‹è½½å¹¶è½¬æ¢ pi0.5 base æ¨¡å‹

> **æ³¨æ„**: Google Drive `dissert_ntu/models/` ä¸­**æ²¡æœ‰** pi05 base PyTorch æ¨¡å‹ã€‚å¿…é¡»ä» GCS å…¬å¼€ bucket ä¸‹è½½ JAX checkpoint å¹¶è½¬æ¢ã€‚

### 10.1 å®‰è£… gsutil

```bash
pip3 install gsutil  # å¦‚æœæ²¡æœ‰
```

### 10.2 åå°ä¸‹è½½ JAX checkpoint (~11.6 GB)

```bash
mkdir -p /workspace/models/pi05_base_jax
gsutil -m cp -r "gs://openpi-assets/checkpoints/pi05_base" \
    /workspace/models/pi05_base_jax/ > /tmp/gsutil.log 2>&1 &
echo "Download PID=$!"
```

ç›‘æ§ï¼š
```bash
sleep 30 && du -sh /workspace/models/pi05_base_jax/ && tail -3 /tmp/gsutil.log
```

> **å®æµ‹è€—æ—¶**: vast.ai æœåŠ¡å™¨ä¸‹è½½ GCS å…¬å¼€ bucket é€Ÿåº¦çº¦ **200â€“500 MiB/s**ï¼Œ11.6 GB çº¦éœ€ **1â€“3 åˆ†é’Ÿ**ã€‚å»ºè®®å’Œ `uv sync`ã€`rclone` ä¸‹è½½åŒæ—¶åå°å¯åŠ¨ã€‚

ä¸‹è½½å®Œæˆåçº¦ 12 GBï¼ŒéªŒè¯ï¼š
```bash
ls /workspace/models/pi05_base_jax/pi05_base/params/
# åº”è¯¥æœ‰ ocdbt.process_0/ ç›®å½•å’Œ commit_success.txt
```

### 10.3 è½¬æ¢ä¸º PyTorch æ ¼å¼

```bash
cd /workspace/openpi
.venv/bin/python examples/convert_jax_model_to_pytorch.py \
    --checkpoint_dir /workspace/models/pi05_base_jax/pi05_base \
    --config_name pi05_libero \
    --output_path /workspace/models/pi05_base_pytorch \
    --precision bfloat16 > /tmp/convert.log 2>&1 &
echo "Conversion PID=$!"
```

> **config_name å¿…é¡»ç”¨ `pi05_libero`**ï¼Œä¸èƒ½ç”¨ `pi05_base`ï¼ˆä¸å­˜åœ¨è¯¥ configï¼‰ã€‚è½¬æ¢çº¦éœ€ **1.5â€“2 åˆ†é’Ÿ**ã€‚

ç›‘æ§ï¼š
```bash
sleep 30 && tail -5 /tmp/convert.log
# æˆåŠŸæ ‡å¿—: "Model conversion completed successfully!"
```

éªŒè¯è¾“å‡ºï¼š
```bash
cd /workspace/openpi && .venv/bin/python -c "
from safetensors.torch import load_file
t = load_file('/workspace/models/pi05_base_pytorch/model.safetensors', device='cpu')
print(f'Total keys: {len(t)}')           # 812
print('action_in_proj:', t['action_in_proj.weight'].shape)  # [1024, 32]
print('time_mlp_in:', t['time_mlp_in.weight'].shape)        # [1024, 1024]
"
```

---

## 11. é…ç½® wandb

wandb ä½¿ç”¨æ–°ç‰ˆ API keyï¼ˆ`wandb_v1_` å‰ç¼€ï¼‰ï¼Œ**ä¸èƒ½ç”¨ `wandb login` å‘½ä»¤**ï¼ˆåªæ¥å— 40 å­—ç¬¦æ—§æ ¼å¼ï¼‰ã€‚æ”¹ç”¨ç¯å¢ƒå˜é‡æˆ–å†™å…¥ netrcï¼š

```bash
# æ–¹æ³• Aï¼šç¯å¢ƒå˜é‡ï¼ˆæ¨èï¼Œæ¯æ¬¡å¯åŠ¨è®­ç»ƒæ—¶è®¾ç½®ï¼‰
export WANDB_API_KEY=<your_wandb_api_key>

# æ–¹æ³• Bï¼šå†™å…¥ netrcï¼ˆæŒä¹…åŒ–ï¼‰
echo "machine api.wandb.ai
  login user
  password <your_wandb_api_key>" >> ~/.netrc
chmod 600 ~/.netrc
```

éªŒè¯ï¼š

> **æ³¨æ„**: `wandb.Api().viewer` åœ¨æ–°ç‰ˆ key ä¸‹å¯èƒ½è¿”å›å¼‚å¸¸ï¼Œ**ä¸å»ºè®®**ç”¨æ­¤å‘½ä»¤åšé¢„éªŒè¯ã€‚çœŸæ­£çš„éªŒè¯åœ¨è®­ç»ƒå¯åŠ¨åâ€”â€”æ—¥å¿—ä¸­å‡ºç° `wandb: ğŸš€ View run at https://...` å³è¡¨ç¤ºè¿æ¥æˆåŠŸï¼ˆè§ç¬¬ 13 èŠ‚ï¼‰ã€‚
>
> å¦‚éœ€æå‰ç¡®è®¤ key æœ‰æ•ˆï¼Œæ£€æŸ¥ `~/.netrc` æ–‡ä»¶ä¸­çš„å†…å®¹æ˜¯å¦æ­£ç¡®å†™å…¥å³å¯ï¼š
> ```bash
> grep -A2 "api.wandb.ai" ~/.netrc
> ```

---

## 12. å¯åŠ¨è®­ç»ƒ

### 12.1 ç¡®è®¤æ‰€æœ‰è·¯å¾„å­˜åœ¨

```bash
# ä¸€æ¬¡æ€§æ£€æŸ¥æ‰€æœ‰å¿…éœ€è·¯å¾„
ls /workspace/data/libero/libero_object_no_noops/libero_object_no_noops/1.0.0/dataset_info.json && echo "âœ“ RLDS"
ls /workspace/data/libero/libero_object_wp_001/waypoint_indices.json && echo "âœ“ waypoint_indices"
ls /workspace/data/libero_object_no_noops/1.0.0/dataset_statistics.json && echo "âœ“ stats"
ls /workspace/models/pi05_base_pytorch/model.safetensors && echo "âœ“ model"
nvidia-smi --query-gpu=name,memory.total --format=csv,noheader
```

### 12.2 åˆ›å»º tmux session å¹¶å¯åŠ¨

> **âš ï¸ tmux æ“ä½œè§„åˆ™**:
> - æ¯æ¬¡ `send-keys` **åªå‘ä¸€æ¡å‘½ä»¤**ï¼Œç”¨ `sleep 2` é—´éš”ç­‰ bash æ‰§è¡Œå®Œ
> - ä¸è¦æ‹¼æ¥ `export VAR=... && torchrun ...`ï¼Œä¼šå¯¼è‡´ bash è§£æé”™è¯¯
> - å¦‚æœ session ä¹‹å‰å´©æºƒè¿‡ï¼Œå…ˆ `tmux kill-session -t waypoint_ae` å†é‡å»º

```bash
# åˆ›å»ºæ–° session
tmux kill-session -t waypoint_ae 2>/dev/null; sleep 1
tmux new-session -d -s waypoint_ae -x 220 -y 50

# æ¯æ¡ send-keys åªå‘ä¸€ä¸ªå‘½ä»¤ï¼Œä¹‹é—´ sleep 2 ç­‰ bash æ‰§è¡Œå®Œ
tmux send-keys -t waypoint_ae "cd /workspace/openpi" Enter
sleep 2
tmux send-keys -t waypoint_ae "export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True" Enter
sleep 2
tmux send-keys -t waypoint_ae "export WANDB_API_KEY=<your_key>" Enter
sleep 2

# åˆ›å»ºæ—¥å¿—ç›®å½•ï¼ˆåœ¨ tmux å¤–æ‰§è¡Œå³å¯ï¼‰
mkdir -p /workspace/openpi/logs

# å¯åŠ¨è®­ç»ƒ
tmux send-keys -t waypoint_ae ".venv/bin/torchrun --standalone --nnodes=1 --nproc_per_node=2 scripts/train_waypoint.py --mode ae --config configs/waypoint_ae_libero.yaml 2>&1 | tee logs/waypoint_ae_libero.log" Enter
```

### 12.4 ç¡®è®¤ VLM è®­ç»ƒè·¯å¾„

```bash
ls /workspace/data/libero/libero_object_wp_001/waypoint_filtered_rlds__libero/1.0.0/dataset_info.json && echo "âœ“ VLM RLDS"
ls /workspace/data/libero/libero_object_wp_001/norm_stats/dataset_statistics.json && echo "âœ“ VLM stats"
ls /workspace/models/pi05_base_pytorch/model.safetensors && echo "âœ“ model"
```

### 12.5 å¯åŠ¨ VLM è®­ç»ƒ

> **VLM ä¸ AE è®­ç»ƒçš„å…³é”®åŒºåˆ«**:
>
> | | AE | VLM |
> |---|---|---|
> | æ¨¡å‹ | PaliGemma + ActionExpert (3.6B) | PaliGemma only (2.9B) |
> | Loss | MSE (flow matching) | CE (autoregressive token) |
> | batch_size (per GPU) | 144 | **12**ï¼ˆVLM åºåˆ—æ›´é•¿, å…¨é‡ finetune 2.9B éœ€æ›´å¤šå†…å­˜ï¼‰ |
> | GPU å†…å­˜ | ~50-60 GB | **~91-93 GB**ï¼ˆå¿…é¡»è®¾ `expandable_segments`ï¼‰ |
> | Gradient Checkpointing | æ‰‹åŠ¨é€å±‚ checkpoint (gemma_pytorch.py) | HuggingFace API è‡ªåŠ¨ checkpoint |
> | æ•°æ®å¯åŠ¨ | ~10sï¼ˆearly-yieldï¼‰ | ~8sï¼ˆåŒæ · early-yieldï¼‰ |
>
> **å¿…é¡»**ä½¿ç”¨ `.venv/bin/torchrun`ï¼ˆç³»ç»Ÿ torchrun ä½¿ç”¨é”™è¯¯çš„ Python è§£é‡Šå™¨ï¼‰ã€‚
> **å¿…é¡»**è®¾ç½® `PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True`ï¼ˆå¦åˆ™ CUDA å†…å­˜ç¢ç‰‡åŒ–å¯¼è‡´ OOMï¼‰ã€‚

```bash
# åˆ›å»ºæ–° sessionï¼ˆå¦‚æœå·²æœ‰åŒå sessionï¼Œå…ˆæ€æ‰ï¼‰
tmux kill-session -t waypoint_vlm 2>/dev/null; sleep 1
tmux new-session -d -s waypoint_vlm -x 220 -y 50

# é€æ¡å‘é€å‘½ä»¤
tmux send-keys -t waypoint_vlm "cd /workspace/openpi" Enter
sleep 2
tmux send-keys -t waypoint_vlm "export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True" Enter
sleep 2
tmux send-keys -t waypoint_vlm "export WANDB_API_KEY=<your_key>" Enter
sleep 2

# åˆ›å»ºæ—¥å¿—ç›®å½•
mkdir -p /workspace/openpi/logs

# å¯åŠ¨ VLM è®­ç»ƒ
tmux send-keys -t waypoint_vlm ".venv/bin/torchrun --standalone --nnodes=1 --nproc_per_node=2 scripts/train_waypoint.py --mode vlm --config configs/waypoint_vlm_libero.yaml 2>&1 | tee logs/waypoint_vlm_libero.log" Enter
```

> **æ–­ç‚¹ç»­è®­**: è¿½åŠ  `--resume` å‚æ•°å³å¯ä»æœ€æ–° checkpoint æ¢å¤ã€‚

---

## 13. éªŒè¯è®­ç»ƒæ­£å¸¸

### 13.1 éªŒè¯ AE è®­ç»ƒ

ç­‰å¾… 30 ç§’åå¼€å§‹æ£€æŸ¥ï¼š

```bash
sleep 30 && tail -20 /workspace/openpi/logs/waypoint_ae_libero.log
```

æŒ‰é¡ºåºåº”å‡ºç°ä»¥ä¸‹å…³é”®è¡Œï¼š

| é¡ºåº | å…³é”®æ—¥å¿— | å«ä¹‰ |
|-----|---------|------|
| 1 | `WaypointAEDataset: 454 episodes, 8409 valid pairs` | æ•°æ®é›†åŠ è½½æˆåŠŸ |
| 2 | `Loaded 811 weight tensors, skipped 1` | pi0.5 æƒé‡åŠ è½½ï¼ˆtime_mlp_in å›  shape å˜åŒ–è¢«è·³è¿‡ï¼Œæ­£å¸¸ï¼‰ |
| 3 | `Constructing tf.data.Dataset libero_object` | RLDS æ•°æ®è¯»å–å¼€å§‹ |
| 4 | `wandb: ğŸš€ View run at https://...` | wandb è¿æ¥æˆåŠŸ |
| 5 | `Model: 3617.8M total, 3617.8M trainable` | æ¨¡å‹åˆå§‹åŒ–æˆåŠŸ |
| 6 | `[AE] step=0/10000 loss=0.xxx` | **ç¬¬ä¸€æ­¥ lossï¼Œè®­ç»ƒå¼€å§‹** |

åˆå§‹ loss åº”åœ¨ 0.7â€“1.0 èŒƒå›´ï¼Œéšåå¿«é€Ÿä¸‹é™åˆ° 0.2â€“0.3ã€‚

å¦‚æœ 30 ç§’åæ—¥å¿—è¿˜åœ¨ step=0ï¼Œè¯´æ˜ RLDS æ•°æ®ç®¡é“åœ¨åˆå§‹åŒ–ï¼Œç»§ç»­ç­‰å¾…ï¼ˆæœ€å¤š 90 ç§’ï¼‰ã€‚

### 13.2 éªŒè¯ VLM è®­ç»ƒ

```bash
sleep 30 && tail -20 /workspace/openpi/logs/waypoint_vlm_libero.log
```

æŒ‰é¡ºåºåº”å‡ºç°ä»¥ä¸‹å…³é”®è¡Œï¼š

| é¡ºåº | å…³é”®æ—¥å¿— | å«ä¹‰ |
|-----|---------|------|
| 1 | `WaypointVLMDataset: dir=...1.0.0, M=7, stride=4, robot=libero` | æ•°æ®é›†åˆ›å»ºæˆåŠŸ |
| 2 | `PaliGemma weights loaded: 603 params, 1 missing, 0 unexpected` | æƒé‡åŠ è½½æˆåŠŸï¼ˆ1 missing æ­£å¸¸ï¼‰ |
| 3 | `Model: 2923.3M total, 2923.3M trainable` | æ¨¡å‹åˆå§‹åŒ–æˆåŠŸ |
| 4 | `wandb: ğŸš€ View run at https://...` | wandb è¿æ¥æˆåŠŸ |
| 5 | `Constructing tf.data.Dataset waypoint_filtered_rlds` | RLDS æ•°æ®è¯»å– |
| 6 | `[VLM] step=0/30000 loss=11.xxx` | **ç¬¬ä¸€æ­¥ lossï¼Œè®­ç»ƒå¼€å§‹** |

**VLM å…³é”®æŒ‡æ ‡**:
- åˆå§‹ CE loss åº”åœ¨ **11â€“12** èŒƒå›´ï¼ˆæ­£å¸¸ï¼Œå› ä¸º vocab size å¾ˆå¤§ï¼‰
- å‰ 50 æ­¥å¿«é€Ÿä¸‹é™åˆ° **6â€“7**ï¼Œ500 æ­¥ååˆ° **4â€“5**
- é€Ÿåº¦çº¦ **3.1â€“3.3 s/step**ï¼ˆDDP 2 å¡ï¼Œbatch_size=12/GPUï¼‰
- GPU å†…å­˜çº¦ **91â€“93 GB** per GPUï¼ˆæ­£å¸¸ï¼Œéå¸¸æ¥è¿‘ä¸Šé™ï¼‰

```bash
# æ£€æŸ¥ GPU ä½¿ç”¨
nvidia-smi --query-gpu=index,memory.used,memory.total --format=csv
# æœŸæœ›: ä¸¤å¡å„ ~91000-93000 MiB / 97887 MiB
```

> **å¦‚æœ VLM å¯åŠ¨åå‡ ç§’å°± OOM**ï¼Œæ£€æŸ¥ï¼š
> 1. `PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True` æ˜¯å¦è®¾ç½®
> 2. æ˜¯å¦ä½¿ç”¨äº† `.venv/bin/torchrun`ï¼ˆä¸æ˜¯ç³»ç»Ÿ torchrunï¼‰
> 3. batch_size æ˜¯å¦ä¸º 12ï¼ˆconfig æ–‡ä»¶ä¸­ç¡®è®¤ï¼‰

---

## 14. å·²çŸ¥é—®é¢˜ä¸ä¿®å¤æ–¹æ¡ˆ

### é—®é¢˜ 1ï¼š`uv sync` å¤±è´¥ â€” `av` åŒ…éœ€è¦ ffmpeg 7

```
Warning! You are installing from source. It is EXPECTED that it will fail. 
You are REQUIRED to use ffmpeg 7.
```

**åŸå› **: `lerobot` ä¾èµ– `av>=14`ï¼Œè€Œ Ubuntu 22/24 ç³»ç»Ÿè‡ªå¸¦ ffmpeg 6ï¼Œæ— é¢„ç¼–è¯‘ wheelã€‚

**ä¿®å¤**: åœ¨ `pyproject.toml` `[tool.uv]` æ®µæ·»åŠ  overrideï¼š
```toml
override-dependencies = ["ml-dtypes==0.4.1", "tensorstore==0.1.74", "av>=13.1.0,<14.0.0"]
```
`av 13.1.0` æœ‰é¢„ç¼–è¯‘ manylinux wheelï¼Œå…¼å®¹ ffmpeg 6ã€‚

> **æ³¨æ„**: `pytorch_lora_blackwell` åˆ†æ”¯å·²é¢„ç½®æ­¤ overrideï¼Œé€šå¸¸æ— éœ€æ‰‹åŠ¨ä¿®æ”¹ã€‚é‡åˆ°æ­¤æŠ¥é”™å‰å…ˆç”¨ `grep "override-dependencies" pyproject.toml` ç¡®è®¤ï¼ˆè§ç¬¬ 4.1 èŠ‚ï¼‰ã€‚

---

### é—®é¢˜ 2ï¼šè®­ç»ƒå´©æºƒ â€” action ç»´åº¦å¹¿æ’­å¤±è´¥

```
ValueError: operands could not be broadcast together with shapes (148,7) (15,)
```

**åŸå› **: `dataset_statistics.json` é‡Œ action ç»´åº¦ï¼ˆ15ï¼‰ä¸ LIBERO å®é™… actionï¼ˆ7ï¼‰ä¸åŒ¹é…ã€‚Google Drive ä¸Šå­˜äº†å¤šä»½ stats æ–‡ä»¶ï¼Œå¤§å¤šæ•°æ˜¯ä¸º VLM è®­ç»ƒæˆ–å…¶ä»–æœºå™¨äººç”Ÿæˆçš„ï¼Œä¸èƒ½ç›´æ¥ç”¨äº LIBERO AE è®­ç»ƒã€‚

**ä¿®å¤**: ä» LIBERO RLDS æ•°æ®é‡æ–°è®¡ç®— statsï¼ˆè§ç¬¬ 9 èŠ‚ï¼‰ã€‚

---

### é—®é¢˜ 3ï¼šproprio ç»´åº¦é”™è¯¯ï¼ˆ7 ç»´è€Œé 8 ç»´ï¼‰

**åŸå› **: LIBERO RLDS observation ä¸­æœ‰ `"joint_state"`ï¼ˆ7 ç»´ï¼‰å’Œ `"state"`ï¼ˆ8 ç»´ï¼‰ä¸¤ä¸ª keyï¼Œå®¹æ˜“ææ··ã€‚`robot_config.py` æŒ‡å®šç”¨ `"state"`ï¼ŒåŒ…å« 7 å…³èŠ‚ + 1 å¤¹çˆª = 8 ç»´ã€‚

**ä¿®å¤**: è®¡ç®— stats æ—¶æ˜ç¡®ç”¨ `step['observation']['state']`ï¼Œä¸ç”¨ `joint_state`ã€‚

---

### é—®é¢˜ 4ï¼š`wandb login` æŠ¥ key é•¿åº¦é”™è¯¯

```
ValueError: API key must be 40 characters long, yours was 86
```

**åŸå› **: æ–°ç‰ˆ wandb API key æ ¼å¼ä¸º `wandb_v1_...`ï¼ˆ86 å­—ç¬¦ï¼‰ï¼Œæ—§ç‰ˆ CLI ä¸æ”¯æŒã€‚

**ä¿®å¤**: ç”¨ç¯å¢ƒå˜é‡ `WANDB_API_KEY=<key>` ä»£æ›¿ `wandb login`ï¼Œæˆ–å†™å…¥ `~/.netrc`ã€‚

---

### é—®é¢˜ 5ï¼štmux è®­ç»ƒå‘½ä»¤è¢« bash è§£æä¸º `export` å‚æ•°

```
-bash: export: `--standalone': not a valid identifier
```

**åŸå› **: åœ¨ä¹‹å‰çš„ tmux session ä¸­æœ‰æœªå®Œæˆçš„ `export` å‘½ä»¤ï¼Œåç»­ `send-keys` å‘çš„è®­ç»ƒå‘½ä»¤è¢«è¿½åŠ åˆ°äº† `export` è¯­å¥åé¢ã€‚

**ä¿®å¤**: å‘ç°å¼‚å¸¸æ—¶ï¼Œå…ˆ `tmux kill-session -t waypoint_ae` æ€æ‰æ—§ sessionï¼Œå†é‡å»ºï¼Œæ¯æ¡ `send-keys` é—´åŠ  `sleep 2`ã€‚

---

### é—®é¢˜ 6ï¼šè®­ç»ƒé€Ÿåº¦ ~14s/stepï¼ˆAEï¼Œæ­£å¸¸æ— éœ€æ‹…å¿ƒï¼‰

å½“å‰ç¡¬ä»¶ï¼ˆ2Ã— RTX PRO 6000 Blackwellï¼‰ï¼Œbatch_size=144ï¼Œå…¨é‡ finetune 3.6B å‚æ•°æ—¶ï¼š
- å‰å‡ æ­¥è¾ƒæ…¢ï¼ˆRLDS æ•°æ® prefetch æœª warm upï¼‰
- ç¨³å®šåçº¦ 13â€“14 s/step
- é¢„è®¡æ€»è®­ç»ƒæ—¶é—´ï¼ˆ10000 stepsï¼‰çº¦ **40â€“45 å°æ—¶**

---

### é—®é¢˜ 7ï¼šVLM è®­ç»ƒ OOM â€” batch_size=16 DDP æŠ¥ CUDA out of memory

```
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 15.68 GiB.
```

**åŸå› **: VLM å…¨é‡ finetune PaliGemma 2B æ—¶ï¼Œæ¨¡å‹æƒé‡ + ä¼˜åŒ–å™¨çŠ¶æ€ + æ¿€æ´» â‰ˆ 91 GB/GPUã€‚DDP å¢åŠ æ¢¯åº¦åŒæ­¥ç¼“å†²å’Œè·¨ rank CUDA contextï¼Œbatch_size=16 è¶…å‡ºå•å¡ ~95 GB çš„å®¹é‡ã€‚

**ä¿®å¤**: å°† batch_size è®¾ä¸º **12**ï¼ˆ`configs/waypoint_vlm_libero.yaml`ï¼‰ï¼ŒDDP 2 å¡æœ‰æ•ˆ batch=24ã€‚åŒæ—¶å¿…é¡»è®¾ç½®ç¯å¢ƒå˜é‡ `PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True`ã€‚

---

### é—®é¢˜ 8ï¼šVLM ä½¿ç”¨ç³»ç»Ÿ torchrun å¯åŠ¨æŠ¥ ModuleNotFoundError

```
ModuleNotFoundError: No module named 'safetensors'
```

**åŸå› **: ç³»ç»Ÿ `torchrun`ï¼ˆ`/venv/main/bin/torchrun`ï¼‰ä½¿ç”¨ç³»ç»Ÿ Python (`python3.12`)ï¼Œè€Œé¡¹ç›®ä¾èµ–å®‰è£…åœ¨ `.venv` (python3.11) ä¸­ã€‚

**ä¿®å¤**: å§‹ç»ˆä½¿ç”¨ `.venv/bin/torchrun` å¯åŠ¨ VLM DDP è®­ç»ƒã€‚AE è®­ç»ƒåŒç†ã€‚

---

### é—®é¢˜ 9ï¼šVLM å¯åŠ¨ææ…¢ï¼ˆ>5 åˆ†é’Ÿæ‰å‡º step=0ï¼‰

**åŸå› **: `vlm_dataset.py` çš„ shuffle buffer å¿…é¡»å®Œå…¨å¡«æ»¡æ‰å¼€å§‹ yield ç¬¬ä¸€ä¸ª batchã€‚5000 æ¡ buffer éœ€è¦éå† RLDS çº¦ 5 è½®ã€‚

**ä¿®å¤**: `vlm_dataset.py` çš„ `__iter__` æ–¹æ³•åº”ä½¿ç”¨ early-yield ç­–ç•¥ï¼ˆbuffer æœ‰ 32 æ¡å³å¼€å§‹ yieldï¼‰ï¼Œä¸ `ae_dataset.py` ä¸€è‡´ã€‚æ­¤ä¿®å¤å·²åˆå…¥ `pytorch_lora_blackwell` åˆ†æ”¯ã€‚è‹¥é‡åˆ°æ­¤é—®é¢˜ï¼Œæ£€æŸ¥ `vlm_dataset.py` ç¬¬ 190 è¡Œé™„è¿‘çš„ `__iter__` æ˜¯å¦æœ‰ `min(32, self.shuffle_buffer_size)` é€»è¾‘ã€‚

---

### é—®é¢˜ 10ï¼šVLM Gradient Checkpointing æ— æ•ˆ â€” batch_size=4 å°± OOM

**åŸå› **: `vlm_model.py` ä¸­ `gradient_checkpointing_enable()` ä»…æ‰‹åŠ¨è®¾ç½® `self.paligemma.language_model.gradient_checkpointing = True`ï¼Œè¿™åªä¼šç¦ç”¨ KV cacheï¼Œ**ä¸ä¼š**å‡å°‘æ¿€æ´»å†…å­˜ã€‚HuggingFace çš„ `GemmaDecoderLayer` ç»§æ‰¿è‡ª `GradientCheckpointingLayer`ï¼Œéœ€è¦é€šè¿‡ `model.gradient_checkpointing_enable()` API æ¿€æ´»æ‰èƒ½çœŸæ­£åœ¨æ¯å±‚ `__call__` ä¸­ä½¿ç”¨ checkpointã€‚

**ä¿®å¤**: `vlm_model.py` çš„ `gradient_checkpointing_enable()` æ–¹æ³•åº”è°ƒç”¨ï¼š
```python
self.paligemma.gradient_checkpointing_enable(
    gradient_checkpointing_kwargs={"use_reentrant": False}
)
```
æ­¤ä¿®å¤å·²åˆå…¥ `pytorch_lora_blackwell` åˆ†æ”¯ã€‚ä¿®å¤å batch_size=16 å•å¡å¯ç”¨ï¼Œbatch_size=12 DDP å¯ç”¨ã€‚

---

## 15. å…³é”®è·¯å¾„é€ŸæŸ¥

| èµ„æº | è·¯å¾„ |
|------|------|
| openpi ä»£ç  | `/workspace/openpi/` |
| è®­ç»ƒè„šæœ¬ | `/workspace/openpi/scripts/train_waypoint.py` |
| AE è®­ç»ƒé…ç½® | `/workspace/openpi/configs/waypoint_ae_libero.yaml` |
| VLM è®­ç»ƒé…ç½® | `/workspace/openpi/configs/waypoint_vlm_libero.yaml` |
| Pi0.5 PyTorch æƒé‡ | `/workspace/models/pi05_base_pytorch/model.safetensors` |
| Pi0.5 JAX åŸå§‹ checkpoint | `/workspace/models/pi05_base_jax/pi05_base/` |
| LIBERO RLDS åŸå§‹æ•°æ® | `/workspace/data/libero/libero_object_no_noops/libero_object_no_noops/1.0.0/` |
| Waypoint indices | `/workspace/data/libero/libero_object_wp_001/waypoint_indices.json` |
| Waypoint filtered RLDSï¼ˆVLM ç”¨ï¼‰ | `/workspace/data/libero/libero_object_wp_001/waypoint_filtered_rlds__libero/1.0.0/` |
| **Dataset statisticsï¼ˆAE ç”¨ï¼‰** | `/workspace/data/libero_object_no_noops/1.0.0/dataset_statistics.json` |
| **Dataset statisticsï¼ˆVLM ç”¨ï¼‰** | `/workspace/data/libero/libero_object_wp_001/norm_stats/dataset_statistics.json` |
| AE è®­ç»ƒæ—¥å¿— | `/workspace/openpi/logs/waypoint_ae_libero.log` |
| VLM è®­ç»ƒæ—¥å¿— | `/workspace/openpi/logs/waypoint_vlm_libero.log` |
| AE Checkpoints | `/workspace/openpi/checkpoints/waypoint_ae_libero/` |
| VLM Checkpoints | `/workspace/openpi/checkpoints/waypoint_vlm_libero/` |
| Google Drive æ•°æ®æº | `gg1:dissert_ntu/libero/` |
| Google Drive æ¨¡å‹å­˜æ¡£ | `gg1:dissert_ntu/models/` |

---

## é™„å½•ï¼šå¿«é€Ÿç›‘æ§å‘½ä»¤

```bash
# å®æ—¶ AE è®­ç»ƒè¿›åº¦
tail -f /workspace/openpi/logs/waypoint_ae_libero.log | grep "\[AE\]"

# å®æ—¶ VLM è®­ç»ƒè¿›åº¦
tail -f /workspace/openpi/logs/waypoint_vlm_libero.log | grep "\[VLM\]"

# GPU çŠ¶æ€
watch -n 5 nvidia-smi --query-gpu=name,utilization.gpu,memory.used,memory.total --format=csv,noheader

# æ£€æŸ¥ checkpoint æ˜¯å¦ä¿å­˜
ls -la /workspace/openpi/checkpoints/waypoint_ae_libero/
ls -la /workspace/openpi/checkpoints/waypoint_vlm_libero/

# æŸ¥çœ‹ tmux session
tmux attach -t waypoint_ae   # AE è®­ç»ƒ
tmux attach -t waypoint_vlm  # VLM è®­ç»ƒ
# é€€å‡ºä¸æ€è¿›ç¨‹: Ctrl+B, D
```
